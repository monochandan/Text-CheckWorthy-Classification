{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98d22a50-7fd4-4ca7-b4c5-e0dd0d160efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13db9bce-4e18-460b-a222-6692fde9d7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\looka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\looka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9c2df81f-b055-4626-a221-91d01164f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff038c99-1d57-4882-975e-29c4b26781d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('created_new_train_data/new_11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfcba102-f32b-4cce-97ad-1051d41cc444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence_id', 'Text', 'class_label', 'Tokens', 'sentiment_score_veda',\n",
       "       'sentiment_score_textblob', 'sentiment_score_bert',\n",
       "       'sentiment_score_roberta', 'bert_sent_neg', 'bert_sent_pos',\n",
       "       'roberta_sent_neg', 'roberta_sent_neut', 'roberta_sent_mixed',\n",
       "       'roberta_sent_pos', 'labels', 'names', 'organizations', 'locations',\n",
       "       'dates', 'verbs', 'action_verbs', 'filtered_action_verbs',\n",
       "       'joined_tokens', 'count_verb', 'count_action_verb',\n",
       "       'count_filtered_action_verb', 'count_tokens', 'cleaned_text',\n",
       "       'cleaned_text_length', 'contains_question_mark', 'contains_exclamation',\n",
       "       'contains_ellipsis', 'num_exclamations', 'num_questions',\n",
       "       'num_ellipses', 'punctuation_count', 'converted_embedding',\n",
       "       'text-tfidf', 'Text_length', 'Text_lengths_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e04304c9-5f1b-4c56-b205-4fab5597005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c81c2707-6bf5-40f5-8919-0a5aad732a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df[['Text','names']].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d02958-eae5-4540-9410-936c6968b886",
   "metadata": {},
   "source": [
    "## droping the previous text_length column, creating new text_length colum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6d9cf05-95dd-41e7-a018-162d851e3521",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop('text_length', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "474b61b8-79fd-4f08-931b-0803062975e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_of_text(row):\n",
    "    text = row['Text']\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    row['Text_length'] = len(tokens)\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    row['Text_lengths_words'] = len(filtered_tokens)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19def970-84f1-4a4a-ab9c-44bc7aa2de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.apply(lambda x: get_length_of_text(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4b7fdb7-72d4-4c67-99cc-855e2267f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df[new_df['class_label'] == 'Yes']['Text_lengths_words'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "46a858d4-7dec-42f3-8412-063846230938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_the_columns_values(id):\n",
    "    print(f\"Original Text: {new_df[new_df['Sentence_id'] == id]['Text'].tolist()}\")\n",
    "    print(f\"Tokens: {new_df[new_df['Sentence_id'] == id]['Tokens'].tolist()}\")\n",
    "    print(f\"names: {new_df[new_df['Sentence_id'] == id]['names'].tolist()}\")\n",
    "    print(f\"organizations: {new_df[new_df['Sentence_id'] == id]['organizations'].tolist()}\")\n",
    "    print(f\"locations: {new_df[new_df['Sentence_id'] == id]['locations'].tolist()}\")\n",
    "    print(f\"dates: {new_df[new_df['Sentence_id'] == id]['dates'].tolist()}\")\n",
    "    print(f\"verbs: {new_df[new_df['Sentence_id'] == id]['verbs'].tolist()}\")\n",
    "    print(f\"lemmatized verbs: {new_df[new_df['Sentence_id'] == id]['lemmatized_verb'].tolist()}\")\n",
    "    print(f\"action verbs: {new_df[new_df['Sentence_id'] == id]['action_verbs'].tolist()}\")\n",
    "    print(f\"filtered action verbs: {new_df[new_df['Sentence_id'] == id]['filtered_action_verbs'].tolist()}\")\n",
    "    print(f\"joined tokens: {new_df[new_df['Sentence_id'] == id]['joined_tokens'].tolist()}\")\n",
    "    print(f\"count verbs: {new_df[new_df['Sentence_id'] == id]['count_verb'].tolist()}\")\n",
    "    print(f\"count action verbs: {new_df[new_df['Sentence_id'] == id]['count_action_verb'].tolist()}\")\n",
    "     ###### 'names', 'organizations', 'locations','dates'\n",
    "    print(f\"count action verbs: {new_df[new_df['Sentence_id'] == id]['names'].tolist()}\")\n",
    "    print(f\"count action verbs: {new_df[new_df['Sentence_id'] == id]['organizations'].tolist()}\")\n",
    "    print(f\"count action verbs: {new_df[new_df['Sentence_id'] == id]['locations'].tolist()}\")\n",
    "    print(f\"count action verbs: {new_df[new_df['Sentence_id'] == id]['dates'].tolist()}\")\n",
    "    # print(f\"count action verbs: {new_df[new_df['Sentence_id'] == id]['count_action_verb'].tolist()}\")\n",
    "    # print(f\"count action verbs: {new_df[new_df['Sentence_id'] == id]['count_action_verb'].tolist()}\")\n",
    "    # print(f\"count action verbs: {new_df[new_df['Sentence_id'] == id]['count_action_verb'].tolist()}\")\n",
    "    # print(f\"count action verbs: {new_df[new_df['Sentence_id'] == id]['count_action_verb'].tolist()}\")\n",
    "    # print(f\"count action verbs: {new_df[new_df['Sentence_id'] == id]['count_action_verb'].tolist()}\")\n",
    "    \n",
    "    # print(new_df[new_df['Sentence_id'] == 32025]['filtered_action_verbs'].tolist())\n",
    "    # 'Tokens','names', 'organizations', 'locations',\n",
    "    #        'dates', 'verbs', 'action_verbs', 'filtered_action_verbs',\n",
    "    #        'joined_tokens', 'count_verb', 'count_action_verb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "238d1c79-33c5-47fa-bd77-b91f81435d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: [\"That's what we need more of, Candy.\"]\n",
      "Tokens: [\"['thats', 'candy']\"]\n",
      "names: [1]\n",
      "organizations: [0]\n",
      "locations: [0]\n",
      "dates: [0]\n",
      "verbs: [\"['need']\"]\n",
      "lemmatized verbs: [[\"'s\", 'need']]\n",
      "action verbs: ['[\"\\'s\"]']\n",
      "filtered action verbs: ['[]']\n",
      "joined tokens: ['thats candy']\n",
      "count verbs: [1]\n",
      "count action verbs: [1]\n",
      "count action verbs: [1]\n",
      "count action verbs: [0]\n",
      "count action verbs: [0]\n",
      "count action verbs: [0]\n"
     ]
    }
   ],
   "source": [
    "see_the_columns_values(10170)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea2edb-2039-46ef-903c-5927b080d8fc",
   "metadata": {},
   "source": [
    "## the verb is not lemmatized - so do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5d8001e-b5cd-4caa-9aa9-bb2113aca2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_verbs = [\n",
    "    # To be\n",
    "    'am', 'is', 'are', 'was', 'were', 'been', 'being',\n",
    "    # To have\n",
    "    'have', 'has', 'had', 'having',\n",
    "    # To do\n",
    "    'do', 'does', 'did', 'doing', 'done'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "044c70ec-634a-4b6f-908d-e535012b0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lemmatize_verb(text):\n",
    "    aux_verbs = [\n",
    "    # To be\n",
    "    'am', 'is', 'are', 'was', 'were', 'been', 'being',\n",
    "    # To have\n",
    "    'have', 'has', 'had', 'having',\n",
    "    # To do\n",
    "    'do', 'does', 'did', 'doing', 'done'\n",
    "    ]\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    words_tagged = pos_tag(tokens)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word, tag in words_tagged if tag.startswith('VB')]\n",
    "    return [word for word in lemmatized_words if word not in aux_verbs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "651a5cf9-cc4f-4908-9f6c-e6671b37e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['lemmatized_verb'] = new_df['Text'].apply(extract_lemmatize_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4113105-3edf-42e9-bc6f-1357318da333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>count_tokens</th>\n",
       "      <th>verbs</th>\n",
       "      <th>action_verbs</th>\n",
       "      <th>filtered_action_verbs</th>\n",
       "      <th>joined_tokens</th>\n",
       "      <th>count_verb</th>\n",
       "      <th>count_action_verb</th>\n",
       "      <th>count_filtered_action_verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30313</td>\n",
       "      <td>['campaign', 'caused', 'questioning', 'worries...</td>\n",
       "      <td>8</td>\n",
       "      <td>['know', 'caused']</td>\n",
       "      <td>['know']</td>\n",
       "      <td>['know']</td>\n",
       "      <td>campaign caused questioning worries part leade...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19099</td>\n",
       "      <td>['lets', 'balance', 'budget', 'protect', 'medi...</td>\n",
       "      <td>8</td>\n",
       "      <td>['let', 'balance', 'protect']</td>\n",
       "      <td>['let']</td>\n",
       "      <td>['let']</td>\n",
       "      <td>lets balance budget protect medicare medicaid ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33964</td>\n",
       "      <td>['id', 'mention', 'thing']</td>\n",
       "      <td>3</td>\n",
       "      <td>['like', 'mention']</td>\n",
       "      <td>['like']</td>\n",
       "      <td>['like']</td>\n",
       "      <td>id mention thing</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16871</td>\n",
       "      <td>['must', 'remind', 'democrats', 'controlled', ...</td>\n",
       "      <td>9</td>\n",
       "      <td>['remind', 'controlled', 'wrote']</td>\n",
       "      <td>['remind']</td>\n",
       "      <td>['remind']</td>\n",
       "      <td>must remind democrats controlled congress last...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13150</td>\n",
       "      <td>['take', 'chance', 'effort', 'provide', 'contr...</td>\n",
       "      <td>8</td>\n",
       "      <td>['take', 'make', 'make', 'provide', 'think']</td>\n",
       "      <td>['think']</td>\n",
       "      <td>['think']</td>\n",
       "      <td>take chance effort provide control weapons gre...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13386</td>\n",
       "      <td>['saying', 'effect', 'inflation']</td>\n",
       "      <td>3</td>\n",
       "      <td>['saying', 'going', 'have']</td>\n",
       "      <td>['going']</td>\n",
       "      <td>['going']</td>\n",
       "      <td>saying effect inflation</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28916</td>\n",
       "      <td>['im', 'proud', 'fact', 'violent', 'crime', 's...</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"'m\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>im proud fact violent crime state texas</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10612</td>\n",
       "      <td>['may', 'seen', 'health', 'care', 'premiums']</td>\n",
       "      <td>5</td>\n",
       "      <td>['know', 'seen', 'go']</td>\n",
       "      <td>['seen']</td>\n",
       "      <td>['seen']</td>\n",
       "      <td>may seen health care premiums</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22058</td>\n",
       "      <td>['4', 'trillion', 'everything', 'perfect', 'do...</td>\n",
       "      <td>5</td>\n",
       "      <td>['have', 'do']</td>\n",
       "      <td>['have']</td>\n",
       "      <td>[]</td>\n",
       "      <td>4 trillion everything perfect dont</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18005</td>\n",
       "      <td>['tough', 'decisions']</td>\n",
       "      <td>2</td>\n",
       "      <td>['made']</td>\n",
       "      <td>['made']</td>\n",
       "      <td>['made']</td>\n",
       "      <td>tough decisions</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20688</td>\n",
       "      <td>['served', 'eight', 'house', 'representatives'...</td>\n",
       "      <td>11</td>\n",
       "      <td>['served', 'served', 'specialized', 'looking']</td>\n",
       "      <td>['served']</td>\n",
       "      <td>['served']</td>\n",
       "      <td>served eight house representatives served inte...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14618</td>\n",
       "      <td>['im', 'starting', 'understand']</td>\n",
       "      <td>3</td>\n",
       "      <td>['think', 'know', 'starting', 'understand']</td>\n",
       "      <td>['think']</td>\n",
       "      <td>['think']</td>\n",
       "      <td>im starting understand</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32025</td>\n",
       "      <td>['talk', 'apology', 'really', 'apologizing', '...</td>\n",
       "      <td>19</td>\n",
       "      <td>['talk', 'think', 'apologizing', 'apologizing'...</td>\n",
       "      <td>['think']</td>\n",
       "      <td>['think']</td>\n",
       "      <td>talk apology really apologizing thing apologiz...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19916</td>\n",
       "      <td>['wont', '10', 'millionaires', '14', 'lawyers'...</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>['be']</td>\n",
       "      <td>['be']</td>\n",
       "      <td>wont 10 millionaires 14 lawyers cabinet</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8355</td>\n",
       "      <td>['experience', 'different', 'mine']</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>['been']</td>\n",
       "      <td>[]</td>\n",
       "      <td>experience different mine</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29499</td>\n",
       "      <td>['better', 'awfully', 'careful']</td>\n",
       "      <td>3</td>\n",
       "      <td>['be']</td>\n",
       "      <td>['be']</td>\n",
       "      <td>['be']</td>\n",
       "      <td>better awfully careful</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10170</td>\n",
       "      <td>['thats', 'candy']</td>\n",
       "      <td>2</td>\n",
       "      <td>['need']</td>\n",
       "      <td>[\"'s\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>thats candy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17507</td>\n",
       "      <td>['rape', 'draw', 'moral', 'judgments']</td>\n",
       "      <td>4</td>\n",
       "      <td>['draw']</td>\n",
       "      <td>['draw']</td>\n",
       "      <td>['draw']</td>\n",
       "      <td>rape draw moral judgments</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20839</td>\n",
       "      <td>['public', 'schools', 'meeting', 'call']</td>\n",
       "      <td>4</td>\n",
       "      <td>['meeting']</td>\n",
       "      <td>['meeting']</td>\n",
       "      <td>['meeting']</td>\n",
       "      <td>public schools meeting call</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5733</td>\n",
       "      <td>['comes', 'economic', 'policies', 'essentially...</td>\n",
       "      <td>8</td>\n",
       "      <td>['comes', 'proposing']</td>\n",
       "      <td>['is']</td>\n",
       "      <td>[]</td>\n",
       "      <td>comes economic policies essentially youre prop...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9481</td>\n",
       "      <td>['means', '98', 'american', 'families', '97', ...</td>\n",
       "      <td>9</td>\n",
       "      <td>['means', 'see']</td>\n",
       "      <td>['see']</td>\n",
       "      <td>['see']</td>\n",
       "      <td>means 98 american families 97 small businesses...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2903</td>\n",
       "      <td>['ways', 'restore', 'strength', 'dont', 'requi...</td>\n",
       "      <td>9</td>\n",
       "      <td>['restore', 'require']</td>\n",
       "      <td>['are']</td>\n",
       "      <td>[]</td>\n",
       "      <td>ways restore strength dont require long experi...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2110</td>\n",
       "      <td>['finally', 'medicaid', 'states']</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Medicaid']</td>\n",
       "      <td>['Medicaid']</td>\n",
       "      <td>finally medicaid states</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3187</td>\n",
       "      <td>['moral', 'peace', 'united', 'states', 'peace']</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>['is']</td>\n",
       "      <td>[]</td>\n",
       "      <td>moral peace united states peace</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21897</td>\n",
       "      <td>['concluded', 'cover', 'everybody', 'leave', '...</td>\n",
       "      <td>29</td>\n",
       "      <td>['concluded', 'cover', 'leave', 'save', 'reinv...</td>\n",
       "      <td>['concluded']</td>\n",
       "      <td>['concluded']</td>\n",
       "      <td>concluded cover everybody leave 27 million beh...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>182</td>\n",
       "      <td>['permit', 'buy', 'medicaid']</td>\n",
       "      <td>3</td>\n",
       "      <td>['permit', 'buy']</td>\n",
       "      <td>['is']</td>\n",
       "      <td>[]</td>\n",
       "      <td>permit buy medicaid</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26427</td>\n",
       "      <td>['weve', 'tough', 'aggressive', 'trade', 'poli...</td>\n",
       "      <td>8</td>\n",
       "      <td>['had', 'got']</td>\n",
       "      <td>['had']</td>\n",
       "      <td>[]</td>\n",
       "      <td>weve tough aggressive trade policies weve inte...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14106</td>\n",
       "      <td>['2nd', 'debate', 'offered', 'since', 'sides',...</td>\n",
       "      <td>16</td>\n",
       "      <td>['offered', 'want', 'get', 'said', 'take', 'go...</td>\n",
       "      <td>['said']</td>\n",
       "      <td>['said']</td>\n",
       "      <td>2nd debate offered since sides enterprise zone...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1017</td>\n",
       "      <td>['probably', 'increase', 'extent']</td>\n",
       "      <td>3</td>\n",
       "      <td>['need', 'increase']</td>\n",
       "      <td>['need']</td>\n",
       "      <td>[]</td>\n",
       "      <td>probably increase extent</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1072</td>\n",
       "      <td>['pledge', 'next', 'ten', 'days', 'asking', 'a...</td>\n",
       "      <td>18</td>\n",
       "      <td>['make', 'asking', 'make', 'think', 'do', 'sti...</td>\n",
       "      <td>['make']</td>\n",
       "      <td>['make']</td>\n",
       "      <td>pledge next ten days asking american important...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20158</td>\n",
       "      <td>['theyre', 'ones', 'challenges', 'making', 'pr...</td>\n",
       "      <td>5</td>\n",
       "      <td>['have', 'making', 'going']</td>\n",
       "      <td>[\"'re\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>theyre ones challenges making predictions</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14683</td>\n",
       "      <td>['really', 'cant', 'believe', 'mr', 'bush', 's...</td>\n",
       "      <td>29</td>\n",
       "      <td>['believe', 'trying', 'make', 'read', 'embraci...</td>\n",
       "      <td>['believe']</td>\n",
       "      <td>['believe']</td>\n",
       "      <td>really cant believe mr bush still trying trust...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13343</td>\n",
       "      <td>['additional', 'powers', 'suggest', 'seizure']</td>\n",
       "      <td>4</td>\n",
       "      <td>['suggest', 'seizure']</td>\n",
       "      <td>['seizure']</td>\n",
       "      <td>['seizure']</td>\n",
       "      <td>additional powers suggest seizure</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>13640</td>\n",
       "      <td>['take', 'fair', 'shared', 'sacrifice']</td>\n",
       "      <td>4</td>\n",
       "      <td>['going', 'take', 'shared']</td>\n",
       "      <td>['going']</td>\n",
       "      <td>['going']</td>\n",
       "      <td>take fair shared sacrifice</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>27204</td>\n",
       "      <td>['happen', 'strengthen', 'economy', 'home']</td>\n",
       "      <td>4</td>\n",
       "      <td>['happen', 'have', 'strengthen']</td>\n",
       "      <td>['have']</td>\n",
       "      <td>[]</td>\n",
       "      <td>happen strengthen economy home</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>17582</td>\n",
       "      <td>['matter', 'fact', 'happens', 'quirks', 'admin...</td>\n",
       "      <td>13</td>\n",
       "      <td>['happens', 'administering', 'get', 'did']</td>\n",
       "      <td>['happens']</td>\n",
       "      <td>['happens']</td>\n",
       "      <td>matter fact happens quirks administering taxes...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>171</td>\n",
       "      <td>['weve', 'enough', 'ladies', 'gentlemen']</td>\n",
       "      <td>4</td>\n",
       "      <td>['had']</td>\n",
       "      <td>['had']</td>\n",
       "      <td>[]</td>\n",
       "      <td>weve enough ladies gentlemen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16499</td>\n",
       "      <td>['mr', 'ford', 'changing', 'considerably', 'pr...</td>\n",
       "      <td>6</td>\n",
       "      <td>['changing']</td>\n",
       "      <td>['changing']</td>\n",
       "      <td>['changing']</td>\n",
       "      <td>mr ford changing considerably previous philosophy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>25783</td>\n",
       "      <td>['things', 'nobody', 'knows']</td>\n",
       "      <td>3</td>\n",
       "      <td>['do', 'knows']</td>\n",
       "      <td>['do']</td>\n",
       "      <td>[]</td>\n",
       "      <td>things nobody knows</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>25904</td>\n",
       "      <td>['thats', 'brought', 'leaders', 'washington', ...</td>\n",
       "      <td>6</td>\n",
       "      <td>['brought']</td>\n",
       "      <td>[\"'s\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>thats brought leaders washington days ago</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>16745</td>\n",
       "      <td>['called', 'increase', 'production', 'energy',...</td>\n",
       "      <td>6</td>\n",
       "      <td>['called']</td>\n",
       "      <td>['called']</td>\n",
       "      <td>['called']</td>\n",
       "      <td>called increase production energy united states</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1759</td>\n",
       "      <td>['corporations', 'individuals']</td>\n",
       "      <td>2</td>\n",
       "      <td>['do']</td>\n",
       "      <td>['do']</td>\n",
       "      <td>[]</td>\n",
       "      <td>corporations individuals</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>26856</td>\n",
       "      <td>['things', 'build', 'bridge', '21st', 'century...</td>\n",
       "      <td>8</td>\n",
       "      <td>['build']</td>\n",
       "      <td>['be']</td>\n",
       "      <td>['be']</td>\n",
       "      <td>things build bridge 21st century greatest hist...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7859</td>\n",
       "      <td>['ive', 'critical', 'administration', 'ive', '...</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>['been']</td>\n",
       "      <td>[]</td>\n",
       "      <td>ive critical administration ive critical presi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22249</td>\n",
       "      <td>['long', 'put', 'thats', 'youre']</td>\n",
       "      <td>4</td>\n",
       "      <td>['put', 'going', 'get']</td>\n",
       "      <td>[\"'s\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>long put thats youre</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>26990</td>\n",
       "      <td>['im', 'wear', 'rosecolored', 'glasses', 'come...</td>\n",
       "      <td>8</td>\n",
       "      <td>['going', 'wear', 'colored', 'comes']</td>\n",
       "      <td>['going']</td>\n",
       "      <td>['going']</td>\n",
       "      <td>im wear rosecolored glasses comes russia mr putin</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>24368</td>\n",
       "      <td>['worked', 'prison', 'labor', 'deal']</td>\n",
       "      <td>4</td>\n",
       "      <td>['worked']</td>\n",
       "      <td>['are']</td>\n",
       "      <td>[]</td>\n",
       "      <td>worked prison labor deal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>19031</td>\n",
       "      <td>['thats', 'im', 'fight']</td>\n",
       "      <td>3</td>\n",
       "      <td>['going', 'fight']</td>\n",
       "      <td>[\"'s\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>thats im fight</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20849</td>\n",
       "      <td>['show', 'learning', 'read', 'write', 'add', '...</td>\n",
       "      <td>8</td>\n",
       "      <td>['Show', 'learning', 'read', 'write', 'add', '...</td>\n",
       "      <td>['Show']</td>\n",
       "      <td>['Show']</td>\n",
       "      <td>show learning read write add subtract bonus plans</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>22441</td>\n",
       "      <td>['sure', 'congress']</td>\n",
       "      <td>2</td>\n",
       "      <td>['do']</td>\n",
       "      <td>['do']</td>\n",
       "      <td>[]</td>\n",
       "      <td>sure congress</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>747</td>\n",
       "      <td>['weve', 'treat', 'international', 'crime']</td>\n",
       "      <td>4</td>\n",
       "      <td>['got', 'treat']</td>\n",
       "      <td>['got']</td>\n",
       "      <td>['got']</td>\n",
       "      <td>weve treat international crime</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3935</td>\n",
       "      <td>['yes', 'troops']</td>\n",
       "      <td>2</td>\n",
       "      <td>['think', 'need']</td>\n",
       "      <td>['think']</td>\n",
       "      <td>['think']</td>\n",
       "      <td>yes troops</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>21211</td>\n",
       "      <td>['john', 'mccain', 'learned', 'experience', 'p...</td>\n",
       "      <td>5</td>\n",
       "      <td>['learned']</td>\n",
       "      <td>['learned']</td>\n",
       "      <td>['learned']</td>\n",
       "      <td>john mccain learned experience position</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>13340</td>\n",
       "      <td>['suggested', 'president', 'given', 'weapons',...</td>\n",
       "      <td>16</td>\n",
       "      <td>['suggested', 'given', 'protect']</td>\n",
       "      <td>['suggested']</td>\n",
       "      <td>['suggested']</td>\n",
       "      <td>suggested president given weapons protect nati...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>25218</td>\n",
       "      <td>['happened']</td>\n",
       "      <td>1</td>\n",
       "      <td>['know', 'happened']</td>\n",
       "      <td>['know']</td>\n",
       "      <td>['know']</td>\n",
       "      <td>happened</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence_id                                             Tokens  \\\n",
       "0         30313  ['campaign', 'caused', 'questioning', 'worries...   \n",
       "1         19099  ['lets', 'balance', 'budget', 'protect', 'medi...   \n",
       "2         33964                         ['id', 'mention', 'thing']   \n",
       "3         16871  ['must', 'remind', 'democrats', 'controlled', ...   \n",
       "4         13150  ['take', 'chance', 'effort', 'provide', 'contr...   \n",
       "5         13386                  ['saying', 'effect', 'inflation']   \n",
       "6         28916  ['im', 'proud', 'fact', 'violent', 'crime', 's...   \n",
       "7         10612      ['may', 'seen', 'health', 'care', 'premiums']   \n",
       "8         22058  ['4', 'trillion', 'everything', 'perfect', 'do...   \n",
       "9         18005                             ['tough', 'decisions']   \n",
       "10        20688  ['served', 'eight', 'house', 'representatives'...   \n",
       "11        14618                   ['im', 'starting', 'understand']   \n",
       "12        32025  ['talk', 'apology', 'really', 'apologizing', '...   \n",
       "13        19916  ['wont', '10', 'millionaires', '14', 'lawyers'...   \n",
       "14         8355                ['experience', 'different', 'mine']   \n",
       "15        29499                   ['better', 'awfully', 'careful']   \n",
       "16        10170                                 ['thats', 'candy']   \n",
       "17        17507             ['rape', 'draw', 'moral', 'judgments']   \n",
       "18        20839           ['public', 'schools', 'meeting', 'call']   \n",
       "19         5733  ['comes', 'economic', 'policies', 'essentially...   \n",
       "20         9481  ['means', '98', 'american', 'families', '97', ...   \n",
       "21         2903  ['ways', 'restore', 'strength', 'dont', 'requi...   \n",
       "22         2110                  ['finally', 'medicaid', 'states']   \n",
       "23         3187    ['moral', 'peace', 'united', 'states', 'peace']   \n",
       "24        21897  ['concluded', 'cover', 'everybody', 'leave', '...   \n",
       "25          182                      ['permit', 'buy', 'medicaid']   \n",
       "26        26427  ['weve', 'tough', 'aggressive', 'trade', 'poli...   \n",
       "27        14106  ['2nd', 'debate', 'offered', 'since', 'sides',...   \n",
       "28         1017                 ['probably', 'increase', 'extent']   \n",
       "29         1072  ['pledge', 'next', 'ten', 'days', 'asking', 'a...   \n",
       "30        20158  ['theyre', 'ones', 'challenges', 'making', 'pr...   \n",
       "31        14683  ['really', 'cant', 'believe', 'mr', 'bush', 's...   \n",
       "32        13343     ['additional', 'powers', 'suggest', 'seizure']   \n",
       "33        13640            ['take', 'fair', 'shared', 'sacrifice']   \n",
       "34        27204        ['happen', 'strengthen', 'economy', 'home']   \n",
       "35        17582  ['matter', 'fact', 'happens', 'quirks', 'admin...   \n",
       "36          171          ['weve', 'enough', 'ladies', 'gentlemen']   \n",
       "37        16499  ['mr', 'ford', 'changing', 'considerably', 'pr...   \n",
       "38        25783                      ['things', 'nobody', 'knows']   \n",
       "39        25904  ['thats', 'brought', 'leaders', 'washington', ...   \n",
       "40        16745  ['called', 'increase', 'production', 'energy',...   \n",
       "41         1759                    ['corporations', 'individuals']   \n",
       "42        26856  ['things', 'build', 'bridge', '21st', 'century...   \n",
       "43         7859  ['ive', 'critical', 'administration', 'ive', '...   \n",
       "44        22249                  ['long', 'put', 'thats', 'youre']   \n",
       "45        26990  ['im', 'wear', 'rosecolored', 'glasses', 'come...   \n",
       "46        24368              ['worked', 'prison', 'labor', 'deal']   \n",
       "47        19031                           ['thats', 'im', 'fight']   \n",
       "48        20849  ['show', 'learning', 'read', 'write', 'add', '...   \n",
       "49        22441                               ['sure', 'congress']   \n",
       "50          747        ['weve', 'treat', 'international', 'crime']   \n",
       "51         3935                                  ['yes', 'troops']   \n",
       "52        21211  ['john', 'mccain', 'learned', 'experience', 'p...   \n",
       "53        13340  ['suggested', 'president', 'given', 'weapons',...   \n",
       "54        25218                                       ['happened']   \n",
       "\n",
       "    count_tokens                                              verbs  \\\n",
       "0              8                                 ['know', 'caused']   \n",
       "1              8                      ['let', 'balance', 'protect']   \n",
       "2              3                                ['like', 'mention']   \n",
       "3              9                  ['remind', 'controlled', 'wrote']   \n",
       "4              8       ['take', 'make', 'make', 'provide', 'think']   \n",
       "5              3                        ['saying', 'going', 'have']   \n",
       "6              7                                                 []   \n",
       "7              5                             ['know', 'seen', 'go']   \n",
       "8              5                                     ['have', 'do']   \n",
       "9              2                                           ['made']   \n",
       "10            11     ['served', 'served', 'specialized', 'looking']   \n",
       "11             3        ['think', 'know', 'starting', 'understand']   \n",
       "12            19  ['talk', 'think', 'apologizing', 'apologizing'...   \n",
       "13             6                                                 []   \n",
       "14             3                                                 []   \n",
       "15             3                                             ['be']   \n",
       "16             2                                           ['need']   \n",
       "17             4                                           ['draw']   \n",
       "18             4                                        ['meeting']   \n",
       "19             8                             ['comes', 'proposing']   \n",
       "20             9                                   ['means', 'see']   \n",
       "21             9                             ['restore', 'require']   \n",
       "22             3                                                 []   \n",
       "23             5                                                 []   \n",
       "24            29  ['concluded', 'cover', 'leave', 'save', 'reinv...   \n",
       "25             3                                  ['permit', 'buy']   \n",
       "26             8                                     ['had', 'got']   \n",
       "27            16  ['offered', 'want', 'get', 'said', 'take', 'go...   \n",
       "28             3                               ['need', 'increase']   \n",
       "29            18  ['make', 'asking', 'make', 'think', 'do', 'sti...   \n",
       "30             5                        ['have', 'making', 'going']   \n",
       "31            29  ['believe', 'trying', 'make', 'read', 'embraci...   \n",
       "32             4                             ['suggest', 'seizure']   \n",
       "33             4                        ['going', 'take', 'shared']   \n",
       "34             4                   ['happen', 'have', 'strengthen']   \n",
       "35            13         ['happens', 'administering', 'get', 'did']   \n",
       "36             4                                            ['had']   \n",
       "37             6                                       ['changing']   \n",
       "38             3                                    ['do', 'knows']   \n",
       "39             6                                        ['brought']   \n",
       "40             6                                         ['called']   \n",
       "41             2                                             ['do']   \n",
       "42             8                                          ['build']   \n",
       "43             6                                                 []   \n",
       "44             4                            ['put', 'going', 'get']   \n",
       "45             8              ['going', 'wear', 'colored', 'comes']   \n",
       "46             4                                         ['worked']   \n",
       "47             3                                 ['going', 'fight']   \n",
       "48             8  ['Show', 'learning', 'read', 'write', 'add', '...   \n",
       "49             2                                             ['do']   \n",
       "50             4                                   ['got', 'treat']   \n",
       "51             2                                  ['think', 'need']   \n",
       "52             5                                        ['learned']   \n",
       "53            16                  ['suggested', 'given', 'protect']   \n",
       "54             1                               ['know', 'happened']   \n",
       "\n",
       "     action_verbs filtered_action_verbs  \\\n",
       "0        ['know']              ['know']   \n",
       "1         ['let']               ['let']   \n",
       "2        ['like']              ['like']   \n",
       "3      ['remind']            ['remind']   \n",
       "4       ['think']             ['think']   \n",
       "5       ['going']             ['going']   \n",
       "6          [\"'m\"]                    []   \n",
       "7        ['seen']              ['seen']   \n",
       "8        ['have']                    []   \n",
       "9        ['made']              ['made']   \n",
       "10     ['served']            ['served']   \n",
       "11      ['think']             ['think']   \n",
       "12      ['think']             ['think']   \n",
       "13         ['be']                ['be']   \n",
       "14       ['been']                    []   \n",
       "15         ['be']                ['be']   \n",
       "16         [\"'s\"]                    []   \n",
       "17       ['draw']              ['draw']   \n",
       "18    ['meeting']           ['meeting']   \n",
       "19         ['is']                    []   \n",
       "20        ['see']               ['see']   \n",
       "21        ['are']                    []   \n",
       "22   ['Medicaid']          ['Medicaid']   \n",
       "23         ['is']                    []   \n",
       "24  ['concluded']         ['concluded']   \n",
       "25         ['is']                    []   \n",
       "26        ['had']                    []   \n",
       "27       ['said']              ['said']   \n",
       "28       ['need']                    []   \n",
       "29       ['make']              ['make']   \n",
       "30        [\"'re\"]                    []   \n",
       "31    ['believe']           ['believe']   \n",
       "32    ['seizure']           ['seizure']   \n",
       "33      ['going']             ['going']   \n",
       "34       ['have']                    []   \n",
       "35    ['happens']           ['happens']   \n",
       "36        ['had']                    []   \n",
       "37   ['changing']          ['changing']   \n",
       "38         ['do']                    []   \n",
       "39         [\"'s\"]                    []   \n",
       "40     ['called']            ['called']   \n",
       "41         ['do']                    []   \n",
       "42         ['be']                ['be']   \n",
       "43       ['been']                    []   \n",
       "44         [\"'s\"]                    []   \n",
       "45      ['going']             ['going']   \n",
       "46        ['are']                    []   \n",
       "47         [\"'s\"]                    []   \n",
       "48       ['Show']              ['Show']   \n",
       "49         ['do']                    []   \n",
       "50        ['got']               ['got']   \n",
       "51      ['think']             ['think']   \n",
       "52    ['learned']           ['learned']   \n",
       "53  ['suggested']         ['suggested']   \n",
       "54       ['know']              ['know']   \n",
       "\n",
       "                                        joined_tokens  count_verb  \\\n",
       "0   campaign caused questioning worries part leade...           2   \n",
       "1   lets balance budget protect medicare medicaid ...           3   \n",
       "2                                    id mention thing           2   \n",
       "3   must remind democrats controlled congress last...           3   \n",
       "4   take chance effort provide control weapons gre...           5   \n",
       "5                             saying effect inflation           3   \n",
       "6             im proud fact violent crime state texas           0   \n",
       "7                       may seen health care premiums           3   \n",
       "8                  4 trillion everything perfect dont           2   \n",
       "9                                     tough decisions           1   \n",
       "10  served eight house representatives served inte...           4   \n",
       "11                             im starting understand           4   \n",
       "12  talk apology really apologizing thing apologiz...           9   \n",
       "13            wont 10 millionaires 14 lawyers cabinet           0   \n",
       "14                          experience different mine           0   \n",
       "15                             better awfully careful           1   \n",
       "16                                        thats candy           1   \n",
       "17                          rape draw moral judgments           1   \n",
       "18                        public schools meeting call           1   \n",
       "19  comes economic policies essentially youre prop...           2   \n",
       "20  means 98 american families 97 small businesses...           2   \n",
       "21  ways restore strength dont require long experi...           2   \n",
       "22                            finally medicaid states           0   \n",
       "23                    moral peace united states peace           0   \n",
       "24  concluded cover everybody leave 27 million beh...           7   \n",
       "25                                permit buy medicaid           2   \n",
       "26  weve tough aggressive trade policies weve inte...           2   \n",
       "27  2nd debate offered since sides enterprise zone...           9   \n",
       "28                           probably increase extent           2   \n",
       "29  pledge next ten days asking american important...           6   \n",
       "30          theyre ones challenges making predictions           3   \n",
       "31  really cant believe mr bush still trying trust...          12   \n",
       "32                  additional powers suggest seizure           2   \n",
       "33                         take fair shared sacrifice           3   \n",
       "34                     happen strengthen economy home           3   \n",
       "35  matter fact happens quirks administering taxes...           4   \n",
       "36                       weve enough ladies gentlemen           1   \n",
       "37  mr ford changing considerably previous philosophy           1   \n",
       "38                                things nobody knows           2   \n",
       "39          thats brought leaders washington days ago           1   \n",
       "40    called increase production energy united states           1   \n",
       "41                           corporations individuals           1   \n",
       "42  things build bridge 21st century greatest hist...           1   \n",
       "43  ive critical administration ive critical presi...           0   \n",
       "44                               long put thats youre           3   \n",
       "45  im wear rosecolored glasses comes russia mr putin           4   \n",
       "46                           worked prison labor deal           1   \n",
       "47                                     thats im fight           2   \n",
       "48  show learning read write add subtract bonus plans           6   \n",
       "49                                      sure congress           1   \n",
       "50                     weve treat international crime           2   \n",
       "51                                         yes troops           2   \n",
       "52            john mccain learned experience position           1   \n",
       "53  suggested president given weapons protect nati...           3   \n",
       "54                                           happened           2   \n",
       "\n",
       "    count_action_verb  count_filtered_action_verb  \n",
       "0                   1                           1  \n",
       "1                   1                           1  \n",
       "2                   1                           1  \n",
       "3                   1                           1  \n",
       "4                   1                           1  \n",
       "5                   1                           1  \n",
       "6                   1                           0  \n",
       "7                   1                           1  \n",
       "8                   1                           0  \n",
       "9                   1                           1  \n",
       "10                  1                           1  \n",
       "11                  1                           1  \n",
       "12                  1                           1  \n",
       "13                  1                           1  \n",
       "14                  1                           0  \n",
       "15                  1                           1  \n",
       "16                  1                           0  \n",
       "17                  1                           1  \n",
       "18                  1                           1  \n",
       "19                  1                           0  \n",
       "20                  1                           1  \n",
       "21                  1                           0  \n",
       "22                  1                           1  \n",
       "23                  1                           0  \n",
       "24                  1                           1  \n",
       "25                  1                           0  \n",
       "26                  1                           0  \n",
       "27                  1                           1  \n",
       "28                  1                           0  \n",
       "29                  1                           1  \n",
       "30                  1                           0  \n",
       "31                  1                           1  \n",
       "32                  1                           1  \n",
       "33                  1                           1  \n",
       "34                  1                           0  \n",
       "35                  1                           1  \n",
       "36                  1                           0  \n",
       "37                  1                           1  \n",
       "38                  1                           0  \n",
       "39                  1                           0  \n",
       "40                  1                           1  \n",
       "41                  1                           0  \n",
       "42                  1                           1  \n",
       "43                  1                           0  \n",
       "44                  1                           0  \n",
       "45                  1                           1  \n",
       "46                  1                           0  \n",
       "47                  1                           0  \n",
       "48                  1                           1  \n",
       "49                  1                           0  \n",
       "50                  1                           1  \n",
       "51                  1                           1  \n",
       "52                  1                           1  \n",
       "53                  1                           1  \n",
       "54                  1                           1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[['Sentence_id', 'Tokens', 'count_tokens', 'verbs', 'action_verbs', 'filtered_action_verbs',\n",
    "       'joined_tokens', 'count_verb', 'count_action_verb',\n",
    "       'count_filtered_action_verb']][:55]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6759ec-c809-4d16-a718-87ff416f2dc4",
   "metadata": {},
   "source": [
    "## new_feature - is ner present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9d13a4dd-408c-433c-adeb-f36beb158dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01df9a70-f345-44dd-a93b-54227dbb8a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dd5909c0-eb56-498e-95b5-bdcad983da1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': np.float32(0.9891377), 'index': 7, 'word': 'Ford', 'start': 34, 'end': 38}, {'entity': 'B-MISC', 'score': np.float32(0.9977507), 'index': 37, 'word': 'Great', 'start': 187, 'end': 192}, {'entity': 'I-MISC', 'score': np.float32(0.99522275), 'index': 38, 'word': 'Depression', 'start': 193, 'end': 203}, {'entity': 'B-PER', 'score': np.float32(0.9986865), 'index': 41, 'word': 'Herbert', 'start': 214, 'end': 221}, {'entity': 'I-PER', 'score': np.float32(0.9953231), 'index': 42, 'word': 'Hoover', 'start': 222, 'end': 228}, {'entity': 'B-PER', 'score': np.float32(0.98588413), 'index': 47, 'word': 'Ford', 'start': 252, 'end': 256}]\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"ner\", model = model, tokenizer = tokenizer)\n",
    "example = \"With all due respect to President Ford, I think he ought to be ashamed of mentioning that statement, because we have the highest unemployment rate now than we had at any time between the Great Depression caused by Herbert Hoover and the time President Ford took office.\"\n",
    "ner_result = nlp(example)\n",
    "print(ner_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "07981784-04f5-41f3-8ce0-05267c9020a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['NER'] = new_df['Text'].apply(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f8fcc0d6-cf69-41f6-9456-d9c3b5047f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'entity': 'B-PER',\n",
       "   'score': np.float32(0.99949384),\n",
       "   'index': 9,\n",
       "   'word': 'Bush',\n",
       "   'start': 41,\n",
       "   'end': 45}]]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[new_df['Sentence_id'] == 28340]['NER'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d29298c3-c12b-43f5-916e-a67b0c2c1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_person_present(ner):\n",
    "    if len(ner) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e55cc33-7c0c-42e2-8fbb-0a8879487aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['is_ner_present'] = new_df['NER'].apply(is_person_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c3c23bda-b387-41ce-b303-3e2d4879a03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>NER</th>\n",
       "      <th>is_ner_present</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30313</td>\n",
       "      <td>And so I know that this campaign has caused so...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19099</td>\n",
       "      <td>Now, let's balance the budget and protect Medi...</td>\n",
       "      <td>[{'entity': 'B-MISC', 'score': 0.999326, 'inde...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33964</td>\n",
       "      <td>I'd like to mention one thing.</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16871</td>\n",
       "      <td>I must remind him the Democrats have controlle...</td>\n",
       "      <td>[{'entity': 'B-MISC', 'score': 0.99956876, 'in...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13150</td>\n",
       "      <td>And to take a chance uh - now be - and not mak...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22496</th>\n",
       "      <td>29631</td>\n",
       "      <td>It would be squandered, too, believe me.</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22497</th>\n",
       "      <td>7136</td>\n",
       "      <td>We're not allowed to vote on it.</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <td>181</td>\n",
       "      <td>More Americans at work today than any time in ...</td>\n",
       "      <td>[{'entity': 'B-MISC', 'score': 0.99951553, 'in...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22499</th>\n",
       "      <td>12863</td>\n",
       "      <td>We indicated at that time that we were not goi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22500</th>\n",
       "      <td>11400</td>\n",
       "      <td>Peace in the Middle East is in our nation's in...</td>\n",
       "      <td>[{'entity': 'B-LOC', 'score': 0.9994647, 'inde...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22501 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence_id                                               Text  \\\n",
       "0            30313  And so I know that this campaign has caused so...   \n",
       "1            19099  Now, let's balance the budget and protect Medi...   \n",
       "2            33964                     I'd like to mention one thing.   \n",
       "3            16871  I must remind him the Democrats have controlle...   \n",
       "4            13150  And to take a chance uh - now be - and not mak...   \n",
       "...            ...                                                ...   \n",
       "22496        29631           It would be squandered, too, believe me.   \n",
       "22497         7136                   We're not allowed to vote on it.   \n",
       "22498          181  More Americans at work today than any time in ...   \n",
       "22499        12863  We indicated at that time that we were not goi...   \n",
       "22500        11400  Peace in the Middle East is in our nation's in...   \n",
       "\n",
       "                                                     NER  is_ner_present  \\\n",
       "0                                                     []           False   \n",
       "1      [{'entity': 'B-MISC', 'score': 0.999326, 'inde...            True   \n",
       "2                                                     []           False   \n",
       "3      [{'entity': 'B-MISC', 'score': 0.99956876, 'in...            True   \n",
       "4                                                     []           False   \n",
       "...                                                  ...             ...   \n",
       "22496                                                 []           False   \n",
       "22497                                                 []           False   \n",
       "22498  [{'entity': 'B-MISC', 'score': 0.99951553, 'in...            True   \n",
       "22499                                                 []           False   \n",
       "22500  [{'entity': 'B-LOC', 'score': 0.9994647, 'inde...            True   \n",
       "\n",
       "       labels  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  \n",
       "...       ...  \n",
       "22496       0  \n",
       "22497       1  \n",
       "22498       1  \n",
       "22499       1  \n",
       "22500       0  \n",
       "\n",
       "[22501 rows x 5 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[['Sentence_id','Text', 'NER', 'is_ner_present','labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9124b27-3d3c-4040-85b2-619b4f8084bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
