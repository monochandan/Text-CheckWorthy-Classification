{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7a2a5-ee59-4645-99e3-1152a44b3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loded the dev_train, dev_test data\n",
    "# add all features, what i have done before,\n",
    "# test directly the dev_test data on the rfc_us model\n",
    "# Under-Sampling\t0.7507\t0.5165\t0.5341\t0.5251 \n",
    "#  1                 .76    0.72      0.48      0.58  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c9f38b5-b00a-4843-8c47-3a0baf962306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\looka\\OneDrive\\Documents\\Thesis\\master_thesis\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline\n",
    "# import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "# import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from pprint import pprint \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd85e3b7-4dc0-4a53-a76c-420b765f450a",
   "metadata": {},
   "source": [
    "# 1. Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07fcf8a-3895-417d-b524-0ddb482e015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = pd.read_csv('created_new_train_data/new_10.csv') # checkworthy_english_train dataset with new created features\n",
    "dev_df = pd.read_csv('data/CT24_checkworthy_english/CT24_checkworthy_english/CT24_checkworthy_english_dev.tsv', delimiter = '\\t') # validation during training\n",
    "dev_test_df = pd.read_csv('data/CT24_checkworthy_english/CT24_checkworthy_english/CT24_checkworthy_english_dev-test.tsv', delimiter = '\\t') # validation for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0fce34-1b25-4493-9074-205b514bd51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dev_df[dev_df['class_label'] == 'Yes'].count()) # 238\n",
    "# print(dev_df[dev_df['class_label'] == 'No'].count()) # 794\n",
    "\n",
    "# print(dev_test_df[dev_test_df['class_label'] == 'Yes'].count()) # 108\n",
    "# print(dev_test_df[dev_test_df['class_label'] == 'No'].count()) # 210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29978272-82f3-4a9a-b9b3-921f72d9e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new label from text to 0/1\n",
    "dev_df['label'] = dev_df['class_label'].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b5783a-b114-4826-ae6f-fbb6fc771dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22501, 38)\n",
      "(1032, 4)\n",
      "(318, 3)\n"
     ]
    }
   ],
   "source": [
    "print(new_df.shape)\n",
    "print(dev_df.shape)\n",
    "print(dev_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64193c94-0aae-45fc-8f1b-3caad97e37e6",
   "metadata": {},
   "source": [
    "## Adding new features in the dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd0931c-6bce-4867-871f-9aeeaedc5dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\looka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\looka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5458ff95-a357-493d-b034-867b598f4892",
   "metadata": {},
   "source": [
    "# 2. Generate Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418bfc56-45df-40ef-a97b-653f34508595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove punctuation\n",
    "    text = ''.join([char for char in text if char not in string.punctuation]) # \n",
    "    # tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove stop words\n",
    "    token = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fe0223-2121-46b0-999a-a6155b4c2fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new column name Token\n",
    "dev_df['Tokens'] = dev_df['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b0545-3642-42a5-8cca-3d7e2ed315d9",
   "metadata": {},
   "source": [
    "# 3. Row text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9eee85f-6dca-457e-af13-d87a93ca9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verious_text_length(text):\n",
    "    text_length = len(text)\n",
    "    return text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eabde72-3a63-4b1d-8aba-0b06e0cff2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['text_length'] = dev_df['Text'].apply(verious_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34c71654-5db2-4ee0-b7d3-730ca838b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_text(text):\n",
    "    # lowercase the data\n",
    "    lower_text = text.lower()\n",
    "    # removing the punctuations\n",
    "    remove_punct = ''.join([char for char in lower_text if char not in string.punctuation])\n",
    "    # remove the stop words\n",
    "    words = word_tokenize(remove_punct)\n",
    "    remove_stop_words = [word for word in words if word not in stop_words]\n",
    "    # removing the numbers\n",
    "    # removing the extra space\n",
    "    # replace the repetations of punctuations\n",
    "    # removing emojis\n",
    "    # removing emoticons\n",
    "    # removing contractions\n",
    "    \n",
    "    return ' '.join(remove_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66aa5b-501c-44a3-b6ce-62340f82c108",
   "metadata": {},
   "source": [
    "# 4. clean text and cleaned text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4fe7731-8d3f-476b-9a0b-f5f295752dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['cleaned_text'] = dev_df['Text'].apply(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2641924a-322e-4f03-bd88-70f42eb0e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['cleaned_text_length'] = dev_df['cleaned_text'].apply(verious_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f0bc41b-7cb3-4301-b57a-71e6e46343ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>class_label</th>\n",
       "      <th>label</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>text_length</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>7145</td>\n",
       "      <td>That's not right in America.</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>[Thats, right, America]</td>\n",
       "      <td>28</td>\n",
       "      <td>thats right america</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>7346</td>\n",
       "      <td>I agree, we shouldn't have quotas.</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>[agree, shouldnt, quotas]</td>\n",
       "      <td>34</td>\n",
       "      <td>agree shouldnt quotas</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence_id                                Text class_label  label  \\\n",
       "299         7145        That's not right in America.          No      0   \n",
       "310         7346  I agree, we shouldn't have quotas.          No      0   \n",
       "\n",
       "                        Tokens  text_length           cleaned_text  \\\n",
       "299    [Thats, right, America]           28    thats right america   \n",
       "310  [agree, shouldnt, quotas]           34  agree shouldnt quotas   \n",
       "\n",
       "     cleaned_text_length  \n",
       "299                   19  \n",
       "310                   21  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dc197d0-b8fe-4a38-acf8-f64f721ca009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\looka\\OneDrive\\Documents\\Thesis\\master_thesis\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\looka\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99a85b92-e27f-434c-9148-30377aecd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_features(text):\n",
    "    # Tokenize the input text\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Perform inference\n",
    "    outputs = model(**tokens)\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    negative, neutral, positive = probs[0].tolist()\n",
    "    \n",
    "    # Define thresholds for \"mixed\" classification (adjust as needed)\n",
    "    if max([positive, negative, neutral]) == positive and positive > 0.5:\n",
    "        sentiment = \"Positive\"\n",
    "    elif max([positive, negative, neutral]) == negative and negative > 0.5:\n",
    "        sentiment = \"Negative\"\n",
    "    else:\n",
    "        sentiment = \"Mixed\"\n",
    "    \n",
    "    return {\n",
    "        \"positive_score\": positive,\n",
    "        \"negative_score\": negative,\n",
    "        \"neutral_score\": neutral,\n",
    "        \"sentiment_class\": sentiment\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a115e19-9e37-46de-b666-29c43dd0c308",
   "metadata": {},
   "source": [
    "# 5. roberta sentiment generate, then different sentiment put in seperate coulumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de0f7034-1d9f-421c-8ca5-b7d79dd65e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f634514803461aa71bce09e54c2ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_df['roberta_sentiment'] = dev_df['Text'].apply(get_sentiment_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81d4acd4-5bbd-4cb0-b05d-b1fd349d1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df[\"roberta_sent_pos\"] = dev_df[\"roberta_sentiment\"].apply(lambda x: x[\"positive_score\"])\n",
    "dev_df[\"roberta_sent_neg\"] = dev_df[\"roberta_sentiment\"].apply(lambda x: x[\"negative_score\"])\n",
    "dev_df[\"roberta_sent_mixed\"] = dev_df[\"roberta_sentiment\"].apply(lambda x: x[\"neutral_score\"])\n",
    "dev_df[\"roberta_sentiment_class\"] = dev_df[\"roberta_sentiment\"].apply(lambda x: x[\"sentiment_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "137cad64-9c9c-4958-90a5-3e7a724e8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(tokens):\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8803831-a27b-4b10-aa41-0277796f07a2",
   "metadata": {},
   "source": [
    "# 6. token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf8add5b-5e68-4607-88b1-6e5508c422e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['token_length'] = dev_df['Tokens'].apply(count_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab3209-afbe-4649-aff5-fcb7491f78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9550931b-5eb4-489b-a313-ff8b6c77c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bcd4b90-9793-43a9-a68f-fda83fcef730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entities_to_columns(text):\n",
    "    \n",
    "\n",
    "    # # Process each row in the DataFrame\n",
    "    # for text in df[text_column]:\n",
    "    #     # Default counts for each row\n",
    "    names = 0\n",
    "    orgs = 0\n",
    "    dates = 0\n",
    "\n",
    "        # Process text using spaCy\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            names += 1\n",
    "        elif ent.label_ == \"ORG\":\n",
    "            orgs += 1\n",
    "        elif ent.label_ == \"DATE\":\n",
    "            dates += 1\n",
    "\n",
    "    return {\n",
    "        \"names\": names,\n",
    "        \"organizations\": orgs,\n",
    "        \"dates\": dates\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646207bd-c2a2-42b1-8a8c-dd0acd516742",
   "metadata": {},
   "source": [
    "# 7. count name organization and date, then out in the seperate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6f6ed34-45f1-4c2a-94c3-c0a93d91d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['counts'] = dev_df['Text'].apply(count_entities_to_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c18b279-26b3-4809-ae49-3b446ce8badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df[\"names\"] = dev_df[\"counts\"].apply(lambda x: x[\"names\"])\n",
    "dev_df[\"organizations\"] = dev_df[\"counts\"].apply(lambda x: x[\"organizations\"])\n",
    "dev_df[\"dates\"] = dev_df[\"counts\"].apply(lambda x: x[\"dates\"])\n",
    "# df_new[\"sentiment_class\"] = df_new[\"roberta_sentiment\"].apply(lambda x: x[\"sentiment_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "579109e6-16ff-406d-b5e6-7e698dd7f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punctuation(text):\n",
    "    # Define a regular expression pattern to match punctuation characters\n",
    "    punctuation_pattern = r'[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]'\n",
    "    # Find all punctuation marks in the text\n",
    "    punctuation_count = len(re.findall(punctuation_pattern, text))\n",
    "    return punctuation_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff08d676-ada4-4aca-9014-356e34a3baf9",
   "metadata": {},
   "source": [
    "# 8. count punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ec41b61-89e8-496d-9724-4f03b7a746c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['punctuation_count'] = dev_df['Text'].apply(count_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a520b463-2fb3-4cdc-a2e4-34b54ed33a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dc97ba36-6024-4a85-80ff-1804c3fd08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=128, truncation=True, padding=\"max_length\")\n",
    "    output = model(**inputs)\n",
    "    embedding = output.last_hidden_state[:, 0, :]\n",
    "    return embedding.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfabf6c-8c94-40de-a1b5-16350931b8c9",
   "metadata": {},
   "source": [
    "# 9. generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24206e23-5a92-4e16-9d15-6518dec6aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['embedding'] = dev_df['Text'].apply(get_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3824f619-cf68-4037-accf-6f00215b6352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "def convert_to_numpy_array(embd_str):\n",
    "    #print(f\"string: {embd_str}\")\n",
    "    #print(type(embd_str))\n",
    "    # embd_str_clean = embd_str.replace(\"\\n\", \" \").replace(\" \", \" \")\n",
    "    #print(type(embd_str_clean))\n",
    "    #print(f\"string cleansing: {embd_str_clean}\")\n",
    "    # embd_str_clean = embd_str.strip('[]')\n",
    "    #print(type(embd_str_clean))\n",
    "    #print(f\"removing the outer brackets {embd_str_clean}\")\n",
    "    #embd_list = embd_str.split()\n",
    "    #print(f\"Split the string into individual values {embd_list}\")\n",
    "    embed_array = np.array(embd_str, dtype = float)\n",
    "    #print(f\"list to array {embed_array}\")\n",
    "    return embed_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96edea11-f92c-4927-b05f-6df7677ebc75",
   "metadata": {},
   "source": [
    "# 10. renaming the column name , similler to the column name, when the model was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce3e1f35-86e1-4bd6-8825-74e993316e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.rename(columns = {'token_length': 'count_tokens'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bce81a-0ae4-4c47-987b-b86994f48456",
   "metadata": {},
   "source": [
    "# 11. convert the embedding into numpy array for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59cb3f2e-32f0-4de2-a467-3174cebaa4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['converted_embedding'] = dev_df['embedding'].apply(convert_to_numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90c1df56-1e48-43d3-9edf-34ad45c82ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = dev_df.astype({'text_length': 'int32', 'roberta_sent_neg': 'float32', 'roberta_sent_mixed': 'float32', 'roberta_sent_pos': 'float32',\n",
    "               'names': 'int32', 'organizations': 'int32', 'dates': 'int32', 'count_tokens': 'int32', 'cleaned_text_length': 'int32', 'punctuation_count': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffd9326c-5d03-41e5-a3b2-49df7f88288e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768)\n"
     ]
    }
   ],
   "source": [
    "print(dev_df['converted_embedding'].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e27c60-30c8-4588-8b82-53706dee67af",
   "metadata": {},
   "source": [
    "# 12. flatten the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5656ee0c-b2f8-4473-9f94-a1b75f882323",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['flattened_embedding'] = dev_df['converted_embedding'].apply(lambda x: np.squeeze(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50d1c4f0-5987-4e18-8aa5-6047078b6690",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.to_csv('created_new_dev_data/first_dev.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eba57dfc-fa6b-433f-a7ee-0078a111d48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768)\n",
      "(1, 768)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "print(dev_df['embedding'].iloc[0].shape)\n",
    "print(dev_df['converted_embedding'].iloc[0].shape)\n",
    "print(dev_df['flattened_embedding'].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9edcb050-3ad3-493a-a21c-4d5b96303dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestRegressor(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9c71ea2-3894-4102-a66a-a1ae30f8c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Parameters are currently in used:\\n\")\n",
    "# pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7577b8-b1fd-49bd-b7ef-bf240869a8ee",
   "metadata": {},
   "source": [
    "<!-- # n_estimators - number of tree in the forest\n",
    "# max_features - max number of features considered for splitting a node \n",
    "# max_depth - max number of leveled in each decicion tree\n",
    "# min_samples_split - min number of adta points placed in a node before the node is split\n",
    "# min_samples_leaf - min number of data points allowed in a leaf node\n",
    "# bootstrap - methos for resampling data points (with or without replacement) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747ff74-1cbd-4b55-9c74-17f6d029fcf4",
   "metadata": {},
   "source": [
    "<!-- n_estimators = number of trees in the foreset\n",
    "max_features = max number of features considered for splitting a node\n",
    "max_depth = max number of levels in each decision tree\n",
    "min_samples_split = min number of data points placed in a node before the node is split\n",
    "min_samples_leaf = min number of data points allowed in a leaf node\n",
    "bootstrap = method for sampling data points (with or without replacement) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43a4fb8-4e66-4c6a-8bbf-fc993c1d9437",
   "metadata": {},
   "source": [
    "## n_estimators = number of trees in the foreset\n",
    "## max_features = max number of features considered for splitting a node\n",
    "## max_depth = max number of levels in each decision tree\n",
    "## min_samples_split = min number of data points placed in a node before the node is split\n",
    "## min_samples_leaf = min number of data points allowed in a leaf node\n",
    "## bootstrap = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12c71159-5843-4839-87fc-6ac1e11a7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the best model so far\n",
    "# load model rfc us\n",
    "# trained on original train data (not dev data)\n",
    "model_path_rfc_us = 'models/random_forest_tfidf_embeddings_10_features_us.pkl'\n",
    "model_rfc_us = joblib.load(model_path_rfc_us)\n",
    "# predictions_rfc_us = model_rfc_us.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7df21cbf-d883-4916-b236-bf52b8c7bfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'monotonic_cst': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rfc_us.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d2003a-7bc0-463c-8796-7bbd4a7a90bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e33e7bd5-d1d4-4ce4-bedd-ea27a7838aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "     'n_estimators': 800,\n",
    "     'min_samples_split': 5,\n",
    "     'min_samples_leaf': 1,\n",
    "     'max_features': 'sqrt',\n",
    "     'max_depth': 90,\n",
    "     'bootstrap': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98031e5a-9ac4-4791-8dce-8d02686971a6",
   "metadata": {},
   "source": [
    "# first test the dev_test data with the base best model, classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9b90a8b4-6c7c-42ef-a032-b44685e402ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>class_label</th>\n",
       "      <th>label</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>text_length</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_text_length</th>\n",
       "      <th>roberta_sentiment</th>\n",
       "      <th>count_tokens</th>\n",
       "      <th>counts</th>\n",
       "      <th>roberta_sent_pos</th>\n",
       "      <th>roberta_sent_neg</th>\n",
       "      <th>roberta_sent_mixed</th>\n",
       "      <th>roberta_sentiment_class</th>\n",
       "      <th>names</th>\n",
       "      <th>organizations</th>\n",
       "      <th>dates</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>flattened_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>38863</td>\n",
       "      <td>We take care of our vets.</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>[take, care, vets]</td>\n",
       "      <td>25</td>\n",
       "      <td>take care vets</td>\n",
       "      <td>14</td>\n",
       "      <td>{'positive_score': 0.3156950771808624, 'negati...</td>\n",
       "      <td>3</td>\n",
       "      <td>{'names': 0, 'organizations': 0, 'dates': 0}</td>\n",
       "      <td>0.315695</td>\n",
       "      <td>0.092554</td>\n",
       "      <td>0.591751</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.005399604327976704, 0.6046665906906128, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence_id                       Text class_label  label  \\\n",
       "114        38863  We take care of our vets.          No      0   \n",
       "\n",
       "                 Tokens  text_length    cleaned_text  cleaned_text_length  \\\n",
       "114  [take, care, vets]           25  take care vets                   14   \n",
       "\n",
       "                                     roberta_sentiment  count_tokens  \\\n",
       "114  {'positive_score': 0.3156950771808624, 'negati...             3   \n",
       "\n",
       "                                           counts  roberta_sent_pos  \\\n",
       "114  {'names': 0, 'organizations': 0, 'dates': 0}          0.315695   \n",
       "\n",
       "     roberta_sent_neg  roberta_sent_mixed roberta_sentiment_class  names  \\\n",
       "114          0.092554            0.591751                   Mixed      0   \n",
       "\n",
       "     organizations  dates  punctuation_count  \\\n",
       "114              0      0                  0   \n",
       "\n",
       "                                   flattened_embedding  \n",
       "114  [0.005399604327976704, 0.6046665906906128, -0....  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dev_test_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "894ff451-867b-4898-84b1-286731f177bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence_id', 'Text', 'class_label', 'label', 'Tokens', 'text_length',\n",
       "       'cleaned_text', 'cleaned_text_length', 'roberta_sentiment',\n",
       "       'count_tokens', 'counts', 'roberta_sent_pos', 'roberta_sent_neg',\n",
       "       'roberta_sent_mixed', 'roberta_sentiment_class', 'names',\n",
       "       'organizations', 'dates', 'punctuation_count', 'flattened_embedding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_test_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de98dd-f044-45b0-822c-431415c890dd",
   "metadata": {},
   "source": [
    "## Add the same features in the dev_test_df for testing the model (model_rfc_us) on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4820c25a-3075-4dda-ba48-be120ec81c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test = pd.read_csv('created_new_dev_data/first_dev_test.csv')\n",
    "dev_train = pd.read_csv('created_new_dev_data/first_dev_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b5e84bfc-d000-48e1-9a5c-797ef1ef1cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    794\n",
      "1    238\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    210\n",
      "1    108\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dev_train['label'].value_counts())\n",
    "print(dev_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9f1be471-87e7-4496-9522-4689a8cb3c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['label'] = dev_test_df['class_label'].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10680586-d1c0-440e-b197-588bfa24fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['Tokens'] = dev_test_df['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae901dde-a32d-4227-95e1-eddef6050366",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['text_length'] = dev_test_df['Text'].apply(verious_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8711994-c3c8-498c-86f7-9be427b65f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['cleaned_text'] = dev_test_df['Text'].apply(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52a1fa77-15b7-47fc-84c2-d5e626104d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['cleaned_text_length'] = dev_test_df['cleaned_text'].apply(verious_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c9a3252f-a47c-4954-97ac-37a5289d0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['roberta_sentiment'] = dev_test_df['Text'].apply(get_sentiment_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "21dc99a6-9cf1-4b54-bfdc-5210585545a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df[\"roberta_sent_pos\"] = dev_test_df[\"roberta_sentiment\"].apply(lambda x: x[\"positive_score\"])\n",
    "dev_test_df[\"roberta_sent_neg\"] = dev_test_df[\"roberta_sentiment\"].apply(lambda x: x[\"negative_score\"])\n",
    "dev_test_df[\"roberta_sent_mixed\"] = dev_test_df[\"roberta_sentiment\"].apply(lambda x: x[\"neutral_score\"])\n",
    "dev_test_df[\"roberta_sentiment_class\"] = dev_test_df[\"roberta_sentiment\"].apply(lambda x: x[\"sentiment_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "96970063-fd41-48a9-a506-c7897eba58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['token_length'] = dev_test_df['Tokens'].apply(count_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8942fa59-a999-475e-a28f-bc088c2ec326",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['counts'] = dev_test_df['Text'].apply(count_entities_to_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ec78bb0d-b2b6-4eee-b882-de2f8971a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df[\"names\"] = dev_test_df[\"counts\"].apply(lambda x: x[\"names\"])\n",
    "dev_test_df[\"organizations\"] = dev_test_df[\"counts\"].apply(lambda x: x[\"organizations\"])\n",
    "dev_test_df[\"dates\"] = dev_test_df[\"counts\"].apply(lambda x: x[\"dates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b08a3a36-f3f7-413d-95cd-69371ae69e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['punctuation_count'] = dev_test_df['Text'].apply(count_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "500924d9-b55c-4a12-8798-eeb47c0a55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['embedding'] = dev_test_df['Text'].apply(get_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4977e8eb-4091-4cde-bb63-fe2d2231c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df.rename(columns = {'token_length': 'count_tokens'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4a953937-81a4-4400-923a-c778c5b6f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['converted_embedding'] = dev_test_df['embedding'].apply(convert_to_numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9ae75205-6c90-4dd1-8a90-d5d08e1a6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df = dev_test_df.astype({'text_length': 'int32', 'roberta_sent_neg': 'float32', 'roberta_sent_mixed': 'float32', 'roberta_sent_pos': 'float32',\n",
    "               'names': 'int32', 'organizations': 'int32', 'dates': 'int32', 'count_tokens': 'int32', 'cleaned_text_length': 'int32', 'punctuation_count': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5bfc9f74-7576-4118-88bb-d4e720e615e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df['flattened_embedding'] = dev_test_df['converted_embedding'].apply(lambda x: np.squeeze(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6c1f4870-c8c6-4e9d-a830-e5bccfd63596",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df.to_csv('created_new_dev_data/first_dev_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d965ecb9-904a-4693-801f-7b451b38969d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dev_test_df['flattened_embedding'].iloc[0] )# flatten embedding == converted_embedding and shape of both is equal (from checkworthy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "59fea7bf-47fb-4232-8d1e-4034894e0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because flatten embedidng is looked like converted embedding (from checkworthy_2) and dropped both columns are same\n",
    "dev_test_df.drop(['converted_embedding', 'embedding'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "48adf9a9-20a6-4847-9315-9a20e9183b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_df[['text_length', 'roberta_sent_neg', 'roberta_sent_mixed',\n",
    "                            'roberta_sent_pos', 'names', 'organizations', 'dates',\n",
    "                            'count_tokens', 'cleaned_text_length', 'punctuation_count']]\n",
    "\n",
    "dev_test_df = dev_test_df.astype({'text_length': 'int32', 'roberta_sent_neg': 'float32', 'roberta_sent_mixed': 'float32', 'roberta_sent_pos': 'float32',\n",
    "               'names': 'int32', 'organizations': 'int32', 'dates': 'int32', 'count_tokens': 'int32', 'cleaned_text_length': 'int32', 'punctuation_count': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "53706e6e-c1d0-419c-8979-b1c34cd08bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 50)\n",
    "reduced_embeddings = pca.fit_transform(dev_test_df['flattened_embedding'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "89396913-138f-4cb5-b72e-b07105e06fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dev_test_df['Text']\n",
    "vectorizer_path = 'models/tfidf_vectorizer_10000.pkl'\n",
    "tfidf_vect = joblib.load(vectorizer_path) ## loading the trained tfidf vectorizer\n",
    "tfidf_features = tfidf_vect.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4290ef16-a325-4116-9184-2aebe3c22b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_features = dev_test_df[['text_length', 'roberta_sent_neg', 'roberta_sent_mixed',\n",
    "                            'roberta_sent_pos', 'names', 'organizations', 'dates',\n",
    "                            'count_tokens', 'cleaned_text_length', 'punctuation_count']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5f568d95-0f2e-4fb8-818a-8281dead5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_np = np.array(reduced_embeddings)\n",
    "tfidf_features_np = tfidf_features.toarray()\n",
    "additional_features_np = np.array(additional_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "da22d7bc-2434-4436-b2ea-af360daae04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([tfidf_features_np,embeddings_np, additional_features_np])\n",
    "y = dev_test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b11f127b-67ca-4175-94b3-305660d3355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rfc_us.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e33595d3-48ef-454f-b744-42949aba6bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       210\n",
      "           1       0.72      0.48      0.58       108\n",
      "\n",
      "    accuracy                           0.76       318\n",
      "   macro avg       0.75      0.69      0.71       318\n",
      "weighted avg       0.76      0.76      0.75       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8447d3-4acf-47d0-a59a-005a8e97c353",
   "metadata": {},
   "source": [
    "# test the dev_test data with the hyperparameter tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4cc9fb-48e7-4963-b48a-9c9c30069599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62140b1e-a061-4b85-a7d3-ca50874bafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned model without resampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3272ac-cd7c-43c0-a85b-7db2d885d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_the_model(model, test_features ,test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors/test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:.02f}%.'.format(accuracy))\n",
    "    return accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
